{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34a90bb5",
   "metadata": {},
   "source": [
    "## Analyze dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfa14f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('normalised_norestriction.xlsx')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc013c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove Unnamed columns\n",
    "df = df.loc[:,~df.columns.str.startswith('Unnamed:')]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3ca366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze for each column how many non NaN values are present\n",
    "print(df.notnull().sum() / len(df) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab7a935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NaN values with empty string\n",
    "df = df.fillna('')\n",
    "\n",
    "# remove all newlines from cells\n",
    "df = df.replace('\\\\n', ' ', regex=True)\n",
    "# replace all multiple spaces with one space\n",
    "df = df.replace('\\s+', ' ', regex=True)\n",
    "# remove all whitespace from cells\n",
    "df = df.map(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9953f717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add '.jpg' to the file name\n",
    "df.loc[:, 'Filename'] = df.loc[:, 'Filename'].apply(lambda x: x + '.jpg')\n",
    "\n",
    "# rename filename to file_name\n",
    "df = df.rename(columns={'Filename': 'file_name'})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5e1e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that all files exists on disk\n",
    "import os\n",
    "files_which_do_not_exist = []\n",
    "for i in df['file_name']:\n",
    "    file_name = './images/' + str(i)\n",
    "    if not os.path.exists(file_name):\n",
    "        files_which_do_not_exist.append(file_name)\n",
    "print(len(files_which_do_not_exist))\n",
    "print(files_which_do_not_exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cc92b8-d5a0-4905-b8a4-af6bf1cc276d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Layout class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e69f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show disjunct values for each column which has less than 50 unique values\n",
    "for column in df.columns:\n",
    "    if len(df[column].unique()) < 50:\n",
    "        print(column)\n",
    "        print(df[column].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e265bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the images to the folder corresponding to the layout class\n",
    "#import shutil\n",
    "#for index, row in df.iterrows():\n",
    "#    file_name = row['file_name']\n",
    "#    layout_class = row['Layout class']\n",
    "#    os.makedirs('./layout_class/' + layout_class, exist_ok=True)\n",
    "#    shutil.copy('./images/' + file_name, './layout_class/' + layout_class + '/' + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755df03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df['Layout class'].value_counts())\n",
    "\n",
    "dict_replacements = {\n",
    "    'BY-eigener-Typ (abweichend 1)': 'BY-eigener-Typ',\n",
    "    'BY-Eigener-Typ' : 'BY-eigener-Typ',\n",
    "    'HH-NI-NRW-SH-Hauptphase (abweichend 1)': 'HH-NI-NRW-SH-Hauptphase',\n",
    "    'HH-NI-NRW-SH-Hauptphase (abweichend 2)': 'HH-NI-NRW-SH-Hauptphase',\n",
    "    'RLP-Hauptphase (abweichend 2)/Saarland' :  'RLP-Hauptphase (abweichend 1 und 2)',\n",
    "    'RLP-Hauptphase (abweichend 1)' : 'RLP-Hauptphase (abweichend 1 und 2)',\n",
    "    'Auskünfte_Statistisches_Landesamt_NRW (abweichend)': 'Auskünfte_Statistisches_Landesamt_NRW',\n",
    "    'NI-Frühe-Phase' : 'RLP-Hauptphase (abweichend 1 und 2)'\n",
    "}\n",
    "\n",
    "#print(df['Layout class'].replace(dict_replacements).value_counts())\n",
    "df['Layout class'] = df['Layout class'].replace(dict_replacements)\n",
    "\n",
    "df['Layout class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725e3f7c",
   "metadata": {},
   "source": [
    "## Create Dataset\n",
    "\n",
    "- First split it into train validation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803acf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split in training , validation and test set (70%, 15%, 15%)   (80%, 10%, 10%) \n",
    "# stratify by 'Layout class'\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df, test_size=0.30, random_state=256, stratify=df['Layout class'])\n",
    "valid, test = train_test_split(test, test_size=0.50, random_state=256, stratify=test['Layout class'])\n",
    "\n",
    "print(train['Layout class'].value_counts())\n",
    "print(valid['Layout class'].value_counts())\n",
    "print(test['Layout class'].value_counts())\n",
    "\n",
    "# convert all columns to string\n",
    "train = train.astype(str)\n",
    "valid = valid.astype(str)\n",
    "test = test.astype(str)\n",
    "\n",
    "train.shape, valid.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7051dc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a ImageFolder (huggingface) image dataset\n",
    "import shutil\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "\n",
    "def create_image_folder_dataset(df, folder_name):\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "    for index, row in df.iterrows():\n",
    "        file_name = './images/' + str(row['file_name'])\n",
    "        if os.path.exists(file_name):\n",
    "            shutil.copy(file_name, folder_name)\n",
    "        else:\n",
    "            print(f\"File {file_name} does not exist\")\n",
    "    #df.to_csv(folder_name + '/metadata.csv', index=False) # quoting=csv.QUOTE_NONNUMERIC\n",
    "    df.to_json(folder_name + '/metadata.jsonl', lines=True, orient='records', force_ascii=False)\n",
    "\n",
    "\n",
    "selected_columns = ['file_name', 'CompensationOffice1', 'BZKNr', 'Layout class', \n",
    "                    'ApplicantFirstName', 'ApplicantLastName', 'ApplicantAltFirstName', 'ApplicantBirthName', 'ApplicantAltLastName', 'ApplicantBirthDate', 'ApplicantBirthPlace', 'ApplicantCurrentAddress', 'ApplicantMaritalStatus',\n",
    "                    'VictimFirstName',    'VictimLastName',    'VictimAltFirstName',    'VictimBirthName',    'VictimAltLastName',    'VictimBirthDate',    'VictimBirthPlace', 'VictimLastAddress', 'VictimDeathDate', 'VictimDeathPlace']\n",
    "   \n",
    "def raw_projection(df):\n",
    "     return df[selected_columns]\n",
    "\n",
    "def normalized_projection(df):\n",
    "    # remove columns ApplicantBirthDate\n",
    "    df = df.drop(columns=['ApplicantBirthDate', 'VictimBirthDate', 'VictimDeathDate', 'ApplicantCurrentAddress', 'VictimLastAddress'])\n",
    "\n",
    "    #rename columns: ApplicantBirthDateNormalised -> ApplicantBirthDate\n",
    "    df = df.rename(columns={\n",
    "        'ApplicantBirthDateNormalised': 'ApplicantBirthDate', \n",
    "        'VictimBirthDateNormalised': 'VictimBirthDate', \n",
    "        'VictimDeathDateNormalised': 'VictimDeathDate',\n",
    "        'ApplicantCurrentAddressCity': 'ApplicantCurrentAddress',\n",
    "        'VictimLastAddressCity': 'VictimLastAddress'\n",
    "    })\n",
    "    return df[selected_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d392ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_projection(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b54edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_projection(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83db0fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_image_folder_dataset(raw_projection(train), './bzkdata_raw/train')\n",
    "create_image_folder_dataset(raw_projection(valid), './bzkdata_raw/valid')\n",
    "create_image_folder_dataset(raw_projection(test), './bzkdata_raw/test')\n",
    "\n",
    "create_image_folder_dataset(normalized_projection(train), './bzkdata_normalized/train')\n",
    "create_image_folder_dataset(normalized_projection(valid), './bzkdata_normalized/valid')\n",
    "create_image_folder_dataset(normalized_projection(test), './bzkdata_normalized/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7031b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset_raw = load_dataset(\"imagefolder\", data_dir='./bzkdata_raw/')\n",
    "dataset_normalized = load_dataset(\"imagefolder\", data_dir='./bzkdata_normalized/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5338c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_raw['validation'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e657e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset_raw)\n",
    "print(dataset_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1796287d",
   "metadata": {},
   "source": [
    "### Login\n",
    "Check that you are logged in by execute the command `huggingface-cli login`.\n",
    "\n",
    "Then run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d46cf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "repository_name = \"stevhliu/processed_demo\"\n",
    "dataset_raw.push_to_hub(repository_name, \"raw\")\n",
    "dataset_normalized.push_to_hub(repository_name, \"normalized\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
